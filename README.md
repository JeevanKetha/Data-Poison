Data-Poison

This project aims to address the growing security concerns in distributed machine learning (DML) systems. Specifically, it focuses on mitigating data poisoning attacks, where malicious actors can manipulate training data to compromise the model's accuracy and reliability.

Key Features:
Data Poison Detection: Employs advanced techniques like Isolation Forest to identify and remove anomalous data points.
Distributed Training: Implements both Basic DML and Semi-DML architectures for parallel model training.
Performance Evaluation: Compares the accuracy and robustness of different DML approaches.
User-Friendly Interface: Provides a user-friendly interface for dataset upload, model training, and result visualization.
Technologies Used:
Python
TensorFlow/PyTorch
Scikit-learn
NumPy
Pandas
Flask (for web application)
